{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     #for playing with the dataset\n",
    "import numpy as np      #for the mathematical calculation\n",
    "import matplotlib.pyplot as plt  #for ploting the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "\n",
    "dataset=pd.read_csv('Data.csv')\n",
    "x=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,-1:].values\n",
    "# [rowstart : rowEnd , columnStart : columnedn]\n",
    "#this is just the slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for handling the missing values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "i=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "x[:,1:3]=i.fit_transform(x[:,1:3])#this will replace the missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the categorial data\n",
    "#converting the categorial data into numeric value\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "x[:,0]=le.fit_transform(x[:,0])\n",
    "y[:,0]=le.fit_transform(y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note : after the label encoder we get some value like 0,1,2,...n\n",
    "#the machine may assume that 0-high priority 1-next high priority...\n",
    "# so the solution is onehotencoder\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "x = ct.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider the age and salary column \n",
    "#age is in the range [20 -50] and salary is in the range[50K - 83K]\n",
    "#in the ml models we will find the euclidean distance so, here the salary dominate the ans\n",
    "#so inorder to avoid this we need to scaling \n",
    "# 1 standardization - (x-mean)/Standard deviation\n",
    "# 2 normalization   - (x-min)/(max-min)\n",
    "\n",
    "#note : the train_set need to be fit and transform\n",
    "#       the test_set just need to be transform\n",
    "# this is done to scale the train and test set in same scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "x_train=ss.fit_transform(x_train)\n",
    "x_test=ss.transform(x_test)\n",
    "\n",
    "#and no need to do scaling for classification \n",
    "# but we need to do for regression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
